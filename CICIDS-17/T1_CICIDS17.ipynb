{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "# from pomegranate import BayesianNetwork\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "#from sdv.single_table import TVAE, CTGAN\n",
    "from sdv.single_table import TVAESynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from scipy.stats import entropy\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('imp_final_df.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "\n",
    "\n",
    "print('originail shape:', data.shape)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Save the synthetic dataset in a separate dataframe\n",
    "df_ros = pd.DataFrame(X_ros, columns=X_train.columns)\n",
    "df_ros['target'] = y_ros\n",
    "\n",
    "\n",
    "# Display the first few rows of the synthetic dataset\n",
    "print(df_ros.shape)\n",
    "df_ros.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ros.to_csv('df_ros.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "df_smote = pd.DataFrame(X_smote, columns=X_train.columns)\n",
    "df_smote['target'] = y_smote\n",
    "\n",
    "print(df_smote.shape)\n",
    "df_smote.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smote.to_csv('df_smote.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ADASYN\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "df_adasyn = pd.DataFrame(X_adasyn, columns=X_train.columns)\n",
    "df_adasyn['target'] = y_adasyn\n",
    "\n",
    "print(df_adasyn.shape)\n",
    "df_adasyn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adasyn.to_csv('df_adasyn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cluster Centroids\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_cc, y_cc = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "df_cc = pd.DataFrame(X_cc, columns=X_train.columns)\n",
    "df_cc['target'] = y_cc\n",
    "\n",
    "\n",
    "print(df_cc.shape)\n",
    "df_cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc.to_csv('df_cc.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(X_train)\n",
    "X_gmm, y_gmm = gmm.sample(n_samples=len(X_train))\n",
    "\n",
    "df_gmm = pd.DataFrame(X_gmm, columns=X_train.columns)\n",
    "df_gmm['target'] = y_gmm\n",
    "\n",
    "\n",
    "print(df_gmm.shape)\n",
    "df_gmm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gmm.to_csv('df_gmm.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Network\n",
    "\n",
    "# Learn the structure of the Bayesian Network\n",
    "hc = HillClimbSearch(data)\n",
    "best_model = hc.estimate(scoring_method=BicScore(data))\n",
    "\n",
    "# Create a BayesianNetwork model from the learned structure\n",
    "bn = BayesianNetwork(best_model.edges())\n",
    "\n",
    "# After learning the initial structure with HillClimbSearch\n",
    "all_variables = set(data.columns)\n",
    "learned_variables = set([var for edge in best_model.edges() for var in edge])\n",
    "\n",
    "# Identify missing variables\n",
    "missing_variables = all_variables - learned_variables\n",
    "\n",
    "# Add missing variables to the model as independent nodes\n",
    "for variable in missing_variables:\n",
    "    bn.add_node(variable)\n",
    "\n",
    "# Now fit the Bayesian Network with all variables included\n",
    "bn.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "# Generating synthetic data\n",
    "num_samples = data.shape[0]  # Number of synthetic data points to generate\n",
    "synthetic_data = bn.simulate(num_samples, seed=np.random.seed(42))\n",
    "\n",
    "# Convert the generated data into a DataFrame\n",
    "df_bn = pd.DataFrame(synthetic_data)\n",
    "df_bn.to_csv('df_bn.csv', index = False)\n",
    "df_bn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TVAE\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['target'])\n",
    "\n",
    "# Define metadata for the dataset\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data)\n",
    "\n",
    "# TVAE\n",
    "tvae = TVAESynthesizer(metadata)\n",
    "tvae.fit(train_data)\n",
    "synthetic_data = tvae.sample(len(data))\n",
    "X_tvae = synthetic_data.drop(columns='target').values\n",
    "y_tvae = synthetic_data['target'].values\n",
    "\n",
    "\n",
    "\n",
    "df_tvae = pd.DataFrame(X_tvae, columns=X.columns)\n",
    "df_tvae['target'] = y_tvae\n",
    "\n",
    "df_tvae.to_csv('df_tvae.csv', index = False)\n",
    "print(df_tvae.shape)\n",
    "df_tvae.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTGAN\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42, stratify=data['target'])\n",
    "# Define metadata for the dataset\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data)\n",
    "\n",
    "\n",
    "# CTGAN\n",
    "ctgan = CTGANSynthesizer(metadata)\n",
    "ctgan.fit(train_data)\n",
    "\n",
    "synthetic_data = ctgan.sample(len(data))\n",
    "X_ctgan = synthetic_data.drop(columns='target').values\n",
    "y_ctgan = synthetic_data['target'].values\n",
    "\n",
    "df_ctgan = pd.DataFrame(X_ctgan, columns=X_train.columns)\n",
    "df_ctgan['target'] = y_ctgan\n",
    "df_ctgan.to_csv('df_ctgan.csv', index = False)\n",
    "\n",
    "df_ctgan.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTGAN execution time 3511m 55.6 s = 58.53 hours = 2.5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "df = pd.read_csv(\"imp_final_df.csv\")\n",
    "df_ros = pd.read_csv(\"df_ros.csv\")\n",
    "df_smote = pd.read_csv(\"df_smote.csv\")\n",
    "df_adasyn = pd.read_csv(\"df_adasyn.csv\")\n",
    "df_cc = pd.read_csv(\"df_cc.csv\")\n",
    "df_gmm = pd.read_csv(\"df_gmm.csv\")\n",
    "df_tvae = pd.read_csv(\"df_tvae.csv\")\n",
    "df_ctgan = pd.read_csv(\"df_ctgan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix of the original and all oversampled data\n",
    "fig, axes = plt.subplots(4, 3, figsize=(40, 40))\n",
    "sns.heatmap(data.corr(), ax=axes[0, 0], cmap=\"coolwarm\", annot=False, xticklabels=data.corr().columns, yticklabels=data.corr().columns)\n",
    "axes[0, 0].set_title(\"Original Data Correlation Matrix\")\n",
    "sns.heatmap(df_ros.corr(), ax=axes[0, 1], cmap=\"coolwarm\", annot=False, xticklabels=df_ros.corr().columns, yticklabels=df_ros.corr().columns)\n",
    "axes[0, 1].set_title(\"Random Oversampling Correlation Matrix\")\n",
    "sns.heatmap(df_smote.corr(), ax=axes[0, 2], cmap=\"coolwarm\", annot=False, xticklabels=df_smote.corr().columns, yticklabels=df_smote.corr().columns)\n",
    "axes[0, 2].set_title(\"SMOTE Correlation Matrix\")\n",
    "sns.heatmap(df_adasyn.corr(), ax=axes[1, 0], cmap=\"coolwarm\", annot=False, xticklabels=df_adasyn.corr().columns, yticklabels=df_adasyn.corr().columns)\n",
    "axes[1, 0].set_title(\"ADASYN Correlation Matrix\")\n",
    "sns.heatmap(df_cc.corr(), ax=axes[1, 1], cmap=\"coolwarm\", annot=False, xticklabels=df_cc.corr().columns, yticklabels=df_cc.corr().columns)\n",
    "axes[1, 1].set_title(\"Cluster Centroids Correlation Matrix\")\n",
    "sns.heatmap(df_gmm.corr(), ax=axes[1, 2], cmap=\"coolwarm\", annot=False, xticklabels=df_gmm.corr().columns, yticklabels=df_gmm.corr().columns)\n",
    "axes[1, 2].set_title(\"Gaussian Mixture Model Correlation Matrix\")\n",
    "#sns.heatmap(df_bn.corr(), ax=axes[2, 0], cmap=\"coolwarm\", annot=False, xticklabels=df_bn.corr().columns, yticklabels=df_bn.corr().columns)\n",
    "#axes[2, 0].set_title(\"Bayesian Network Correlation Matrix\")\n",
    "sns.heatmap(df_tvae.corr(), ax=axes[2, 1], cmap=\"coolwarm\", annot=False, xticklabels=df_tvae.corr().columns, yticklabels=df_tvae.corr().columns)\n",
    "axes[2, 1].set_title(\"TVAE Correlation Matrix\")\n",
    "sns.heatmap(df_ctgan.corr(), ax=axes[2, 2], cmap=\"coolwarm\", annot=False, xticklabels=df_ctgan.corr().columns, yticklabels=df_ctgan.corr().columns)\n",
    "axes[2, 2].set_title(\"CTGAN Correlation Matrix\")\n",
    "# sns.heatmap(df_ddmp.corr(), ax=axes[3, 0], cmap=\"coolwarm\", annot=False, xticklabels=df_ddmp.corr().columns, yticklabels=df_ddmp.corr().columns)\n",
    "# axes[3, 0].set_title(\"TABDDMP Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrices for the original and synthetic datasets\n",
    "corr_original = data.corr()\n",
    "corr_ros = df_ros.corr()\n",
    "corr_smote = df_smote.corr()\n",
    "corr_adasyn = df_adasyn.corr()\n",
    "corr_cc = df_cc.corr()\n",
    "corr_gmm = df_gmm.corr()\n",
    "#corr_bn = df_bn.corr()\n",
    "corr_tvae = df_tvae.corr()\n",
    "corr_ctgan = df_ctgan.corr()\n",
    "# corr_ddmp = df_ddmp.corr()\n",
    "\n",
    "# Calculate the absolute difference matrices\n",
    "abs_diff_ros = np.abs(corr_original - corr_ros)\n",
    "abs_diff_smote = np.abs(corr_original - corr_smote)\n",
    "abs_diff_adasyn = np.abs(corr_original - corr_adasyn)\n",
    "abs_diff_cc = np.abs(corr_original - corr_cc)\n",
    "abs_diff_gmm = np.abs(corr_original - corr_gmm)\n",
    "#abs_diff_bn = np.abs(corr_original - corr_bn)\n",
    "abs_diff_tvae = np.abs(corr_original - corr_tvae)\n",
    "abs_diff_ctgan = np.abs(corr_original - corr_ctgan)\n",
    "# abs_diff_ddmp = np.abs(corr_original - corr_ddmp)\n",
    "\n",
    "# Plot the absolute difference heatmaps\n",
    "fig, axes = plt.subplots(3, 3, figsize=(40, 40))\n",
    "sns.heatmap(abs_diff_ros, ax=axes[0, 0], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_ros.columns, yticklabels=abs_diff_ros.columns)\n",
    "axes[0, 0].set_title(\"Absolute Difference with Random Oversampling\")\n",
    "sns.heatmap(abs_diff_smote, ax=axes[0, 1], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_smote.columns, yticklabels=abs_diff_smote.columns)\n",
    "axes[0, 1].set_title(\"Absolute Difference with SMOTE\")\n",
    "sns.heatmap(abs_diff_adasyn, ax=axes[0, 2], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_adasyn.columns, yticklabels=abs_diff_adasyn.columns)\n",
    "axes[0, 2].set_title(\"Absolute Difference with ADASYN\")\n",
    "sns.heatmap(abs_diff_cc, ax=axes[1, 0], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_cc.columns, yticklabels=abs_diff_cc.columns)\n",
    "axes[1, 0].set_title(\"Absolute Difference with Cluster Centroids\")\n",
    "sns.heatmap(abs_diff_gmm, ax=axes[1, 1], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_gmm.columns, yticklabels=abs_diff_gmm.columns)\n",
    "axes[1, 1].set_title(\"Absolute Difference with Gaussian Mixture Model\")\n",
    "#sns.heatmap(abs_diff_bn, ax=axes[1, 2], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_bn.columns, yticklabels=abs_diff_bn.columns)\n",
    "#axes[1, 2].set_title(\"Absolute Difference with Bayesian Network\")\n",
    "sns.heatmap(abs_diff_tvae, ax=axes[2, 0], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_tvae.columns, yticklabels=abs_diff_tvae.columns)\n",
    "axes[2, 0].set_title(\"Absolute Difference with TVAE\")\n",
    "sns.heatmap(abs_diff_ctgan, ax=axes[2, 1], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_ctgan.columns, yticklabels=abs_diff_ctgan.columns)\n",
    "axes[2, 1].set_title(\"Absolute Difference with CTGAN\")\n",
    "# sns.heatmap(abs_diff_ddmp, ax=axes[2, 2], cmap=\"coolwarm\", annot=False, xticklabels=abs_diff_ddmp.columns, yticklabels=abs_diff_ddmp.columns)\n",
    "# axes[2, 2].set_title(\"Absolute Difference with TABDDMP\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of DataFrames\n",
    "dfs = [data, df_ros, df_smote, df_adasyn, df_cc, df_gmm, df_tvae, df_ctgan]\n",
    "titles = [\"Original Data\", \"Random Oversampling\", \"SMOTE\", \"ADASYN\", \"Cluster Centroids\", \n",
    "          \"Gaussian Mixture Model\", \"TVAE\", \"CTGAN\"]\n",
    "\n",
    "# Function to compare distributions and calculate KS test results\n",
    "def compare_distributions(real_data, synthetic_datasets, titles):\n",
    "    results = {}\n",
    "    average_results = {}\n",
    "    \n",
    "    for synthetic_data, title in zip(synthetic_datasets, titles):\n",
    "        \n",
    "        ks_results = []\n",
    "        \n",
    "        equal_count = 0\n",
    "        different_count = 0\n",
    "        \n",
    "        for column in real_data.columns:\n",
    "            if column == 'target':\n",
    "                continue\n",
    "            \n",
    "            real_values = real_data[column].values\n",
    "            synthetic_values = synthetic_data[column].values\n",
    "            \n",
    "            # Perform KS Test\n",
    "            ks_statistic, ks_p_value = ks_2samp(real_values, synthetic_values)\n",
    "            \n",
    "            # Store KS test results\n",
    "            ks_results.append({\n",
    "                'Feature': column,\n",
    "                'KS Statistic': ks_statistic,\n",
    "                'KS P-value': ks_p_value\n",
    "            })\n",
    "            \n",
    "            # Count equal and different distributions\n",
    "            if ks_p_value > 0.05:\n",
    "                equal_count += 1\n",
    "            else:\n",
    "                different_count += 1\n",
    "        \n",
    "        # Store results for current synthetic dataset\n",
    "        results[title] = ks_results\n",
    "        \n",
    "        # Calculate average results\n",
    "        total_features = len(real_data.columns) - 1  # excluding target column\n",
    "        average_results[title] = {\n",
    "            'Equal Distributions': equal_count,\n",
    "            'Different Distributions': different_count,\n",
    "            'Average KS P-value': np.mean([result['KS P-value'] for result in ks_results])\n",
    "        }\n",
    "    \n",
    "    # Print average results\n",
    "    print(\"\\n--- Average Results ---\")\n",
    "    for title, avg_res in average_results.items():\n",
    "        print(f\"{title}:\")\n",
    "        print(f\"Equal Distributions: {avg_res['Equal Distributions']}\")\n",
    "        print(f\"Different Distributions: {avg_res['Different Distributions']}\")\n",
    "        print(f\"Average KS P-value: {avg_res['Average KS P-value']}\")\n",
    "        print(\"-----------------------------\")\n",
    "    \n",
    "    return results, average_results\n",
    "\n",
    "# Function to plot KDE plots for all features across all datasets\n",
    "def plot_kde_comparison(real_data, synthetic_datasets, titles, ks_results):\n",
    "    num_datasets = len(synthetic_datasets) + 1  # including original data\n",
    "    num_features = len(real_data.columns) - 1  # excluding target column\n",
    "    \n",
    "    for column in real_data.columns:\n",
    "        if column == 'target':\n",
    "            continue\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i, synthetic_data in enumerate(synthetic_datasets):\n",
    "            sns.kdeplot(synthetic_data[column], label=titles[i])\n",
    "        \n",
    "        sns.kdeplot(real_data[column], label='Original Data', linewidth=3, color='black')\n",
    "        \n",
    "        # Annotate KS test results on the plot\n",
    "        #for result in ks_results:\n",
    "         #   ks_statistic = result['KS Statistic']\n",
    "          #  ks_p_value = result['KS P-value']\n",
    "           # if ks_p_value > 0.05:\n",
    "            #    plt.text(0.98, 0.95 - ks_results.index(result)*0.05, f'{result[\"Feature\"]}: KS p-value={ks_p_value:.3f}', transform=plt.gca().transAxes, ha='right', color='green')\n",
    "            #else:\n",
    "             #   plt.text(0.98, 0.95 - ks_results.index(result)*0.05, f'{result[\"Feature\"]}: KS p-value={ks_p_value:.3f}', transform=plt.gca().transAxes, ha='right', color='red')\n",
    "        \n",
    "        plt.title(f'Probability Distribution of {column}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming `dfs`, `titles`, and `df` are defined as before\n",
    "results, average_results = compare_distributions(data, dfs, titles)\n",
    "plot_kde_comparison(data, dfs, titles, results[titles[1]])  # Display for one synthetic dataset (change index as needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, f1\n",
    "\n",
    "# Initialize results dictionary\n",
    "utility_results = {title: {'TRTR_accuracy': 0, 'TRTR_f1': 0, 'TSTR_accuracy': 0, 'TSTR_f1': 0} for title in titles[1:]}\n",
    "\n",
    "# Evaluate TRTR (Training on Real, Testing on Real)\n",
    "model_trtr = RandomForestClassifier(random_state=42)\n",
    "model_trtr.fit(X_train, y_train)\n",
    "trtr_accuracy, trtr_f1 = evaluate_model(model_trtr, X_test, y_test)\n",
    "utility_results[\"Original Data\"] = {'TRTR_accuracy': trtr_accuracy, 'TRTR_f1': trtr_f1}\n",
    "\n",
    "# Evaluate TSTR (Training on Synthetic, Testing on Real)\n",
    "for i, data in enumerate(dfs[1:], 1):\n",
    "    X_synthetic = data.drop('target', axis=1)\n",
    "    y_synthetic = data['target']\n",
    "    model_tstr = RandomForestClassifier(random_state=42)\n",
    "    model_tstr.fit(X_synthetic, y_synthetic)\n",
    "    tstr_accuracy, tstr_f1 = evaluate_model(model_tstr, X_test, y_test)\n",
    "    utility_results[titles[i]]['TSTR_accuracy'] = tstr_accuracy\n",
    "    utility_results[titles[i]]['TSTR_f1'] = tstr_f1\n",
    "\n",
    "# Display the utility results\n",
    "utility_df = pd.DataFrame(utility_results).T\n",
    "print(\"Utility results (F1 score, accuracy comparison of TRTR and TSTR) for all datasets:\")\n",
    "print(utility_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [data, df_ros, df_smote, df_adasyn, df_cc, df_gmm, df_tvae, df_ctgan]\n",
    "titles = [\"Original Data\", \"Random Oversampling\", \"SMOTE\", \"ADASYN\", \"Cluster Centroids\", \n",
    "          \"Gaussian Mixture Model\", \"TVAE\", \"CTGAN\"]\n",
    "\n",
    "for title, df in zip(titles, dfs):\n",
    "    #print(f\"DataFrame: {title}\")\n",
    "    #print(df.logged_in.value_counts())\n",
    "    #print(df.protocol_type_icmp.value_counts())\n",
    "    #print(df.protocol_type_tcp.value_counts())\n",
    "    #print(df.service_http.value_counts())\n",
    "    #print(df.flag_S0.value_counts())\n",
    "    #print(df.flag_SF.value_counts())\n",
    "    print(df.target.value_counts())\n",
    "    print(\"\\n\")  # Add a newline for better readability between DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
